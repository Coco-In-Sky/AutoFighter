{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用一对多的多分类策略，为每个状态建立单独的分类器，然后分别训练\n",
    "\n",
    "未完成部分\n",
    "- 配置全局参数可以任意指定要训练的模型和对应的数据集\n",
    "- 配置全局参数可以针对指定的模型进行保存和读取\n",
    "- 拆分训练集和验证集\n",
    "- 配置整合函数main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from StatusChecker.TraditionalStatusChecker import TraditionalStatusChecker\n",
    "status_list = list(filter(lambda name: (name.startswith(\"ASC_STATUS_\") and name != 'ASC_STATUS_UNKNOWN'),\n",
    "                                  dir(TraditionalStatusChecker)))\n",
    "status_list = list(map(lambda name: getattr(TraditionalStatusChecker, name), status_list))\n",
    "\n",
    "print(status_list)\n",
    "print(f\"total {len(status_list)} status\")\n",
    "tag_dic = status_list\n",
    "# tag_dic = [\"level_selection\",\n",
    "#            \"restore_sanity_medicine\",\n",
    "#            \"restore_sanity_stone\",\n",
    "#            \"team_up\",\n",
    "#            \"fighting\",\n",
    "#            \"battle_settlement\",\n",
    "#            \"annihilation_settlement\",\n",
    "#            \"level_up\"]\n",
    "\n",
    "current_train_tag = TraditionalStatusChecker.ASC_STATUS_FIGHTING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "根据训练目标选取数据集\n",
    "- 正向数据集选取目标标签，数量选取所有的或者指定阈值\n",
    "- 反向数据集选取其余的标签数据，数量取正向数据集长度平均至每个TAG，不够的暂时全上"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 基础数据集路径\n",
    "train_set_base_path = os.path.join(os.getcwd(), '..', 'dataset', 'processed')\n",
    "\n",
    "# 所有可用标签\n",
    "all_available_tag_data_path_list = os.listdir(train_set_base_path)\n",
    "\n",
    "# 正向数据集路径\n",
    "train_set_positive_data_path = os.path.join(train_set_base_path, current_train_tag)\n",
    "\n",
    "# 反向数据集路径列表\n",
    "train_set_negative_data_path_list = all_available_tag_data_path_list.copy()\n",
    "train_set_negative_data_path_list.remove(current_train_tag)\n",
    "\n",
    "#TODO 如果说数据量不平衡的话，最后那个数据会影响很多东西把\n",
    "\n",
    "\n",
    "train_set_path = os.path.join(os.getcwd(), '..', 'dataset', 'processed')\n",
    "train_file_list = os.listdir(train_set_path)\n",
    "\n",
    "def map_func(filename:str) -> torch.Tensor:\n",
    "    for index, tag in enumerate(tag_dic):\n",
    "        if tag in filename:\n",
    "            return torch.tensor(index, dtype=torch.long, device=torch.device('cuda'))\n",
    "\n",
    "\n",
    "target_list = list(map(map_func, train_file_list))\n",
    "print(len(train_file_list))\n",
    "print(train_file_list[0])\n",
    "print(tag_dic)\n",
    "print(len(target_list))\n",
    "print(target_list[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "配置 DataSet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def default_loader(image_path:str) -> torch.Tensor:\n",
    "    image_loaded = cv.imread(\n",
    "        os.path.join(train_set_path, image_path),\n",
    "        cv.IMREAD_GRAYSCALE)\n",
    "    image_tensor = torch.tensor(image_loaded, device=torch.device('cuda'), dtype=torch.float32).unsqueeze(0)\n",
    "    print(f\"load image {image_path}\")\n",
    "    # print(image_tensor.size())\n",
    "    return image_tensor\n",
    "\n",
    "class TrainSet(Dataset):\n",
    "    def __init__(self, image_name_list:list, targets:int, loader=default_loader)-> None:\n",
    "        self.images = image_name_list\n",
    "        self.targets = targets\n",
    "        self.loader = loader\n",
    "    def __getitem__(self, index: int):\n",
    "        data = self.loader(self.images[index])\n",
    "        target = self.targets[index]\n",
    "        return data, target\n",
    "    def __len__(self)-> int:\n",
    "        return len(self.images)\n",
    "\n",
    "def get_train_set() -> Dataset:\n",
    "\n",
    "    train_set = TrainSet(train_file_list, target_list)\n",
    "    print(train_set)\n",
    "    print(train_set.__getitem__(3))\n",
    "    print(train_set.__len__())\n",
    "    return train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "构建 DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def get_train_loader(train_set:Dataset) -> DataLoader:\n",
    "    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "    print(train_loader)\n",
    "    print(iter(train_loader).next()[0].size())\n",
    "    print(iter(train_loader).next()[1].size())\n",
    "    return train_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Lambda(torch.nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    def forward(self, xb):\n",
    "        return self.func(xb)\n",
    "\n",
    "def get_module():\n",
    "    module = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveAvgPool2d([16, 36]),\n",
    "        Lambda(lambda xb: xb.view(-1, 10*16*36)),\n",
    "        torch.nn.Linear(10*16*36, 16*36),\n",
    "        torch.nn.Linear(16*36, 36),\n",
    "        torch.nn.Linear(36, 1),\n",
    "        torch.nn.Softmax(),\n",
    "    )\n",
    "\n",
    "    learn_rate = 0.1\n",
    "\n",
    "    optimize = torch.optim.SGD(module.parameters(), lr=learn_rate)\n",
    "    return module, optimize\n",
    "\n",
    "def get_loss_function():\n",
    "    loss_func = torch.nn.functional.binary_cross_entropy\n",
    "    return loss_func\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fit() 函数以及模型的保存和恢复"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs:int, module:torch.nn.Module,\n",
    "        loss_function, optimize, train_loader, validate_loader):\n",
    "    index = 0\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            index = index + 1\n",
    "            if index%50 is 0:\n",
    "                print(f\"start index {index} data\")\n",
    "            loss_batch(module, loss_function, xb, yb, optimize)\n",
    "        module.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(module, loss_function, xb, yb)\n",
    "                  for xb, yb in validate_loader]\n",
    "            )\n",
    "        val_loss = numpy.sum(numpy.multiply(losses, nums)) / numpy.sum(nums)\n",
    "        print(epoch, val_loss)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}